{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1183165,"sourceType":"datasetVersion","datasetId":672377}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#240b36;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px; color:white; text-align: center\"> WELCOME TO MY NOTEBOOK </p>\n</div>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<h1 style=\"color:#E83500; text-align: center\"> Title: Brain Tumor Classification with custom Neural Network </font></h1>\n\n<div style=\"display: flex; justify-content: center; align-items: center;\">\n    <img src=\"http://alsani.me/wp-content/uploads/2023/11/MRI-animinated.gif\" alt=\"Centered Image\" style=\"display: block; margin: auto;\">\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"home\"></a>\n\n### Table of contents:\n\n* [Introduction and brief introduction of data](#1)\n* [1. Import Necessary Library](#2)\n* [2. Data Loading and Preprocessing](#3)\n* [3. DenseNet201 function Calling](#4)\n* [5. Now Plot the Training Loss, Validation Loss](#5)\n* [6. Now Predictions for random image](#6)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<div style= \"border-radius:10px; border:#787878 solid; padding: 15px; background-color: #E7E5E4; font-size:100%; text-align:left\">\n\n<h2 style=\"color:#E83500\"> ‚ñ∂Ô∏è Introduction and brief introduction of data</font></h2>\n\n**Introduction**\n\nA Brain tumor is considered as one of the aggressive diseases, among children and adults. Brain tumors account for 85 to 90 percent of all primary Central Nervous System(CNS) tumors. Every year, around 11,700 people are diagnosed with a brain tumor. The 5-year survival rate for people with a cancerous brain or CNS tumor is approximately 34 percent for men and36 percent for women. Brain Tumors are classified as: Benign Tumor, Malignant Tumor, Pituitary Tumor, etc. Proper treatment, planning, and accurate diagnostics should be implemented to improve the life expectancy of the patients. The best technique to detect brain tumors is Magnetic Resonance Imaging (MRI). A huge amount of image data is generated through the scans. These images are examined by the radiologist. A manual examination can be error-prone due to the level of complexities involved in brain tumors and their properties.\n\nApplication of automated classification techniques using Machine Learning(ML) and Artificial Intelligence(AI)has consistently shown higher accuracy than manual classification. Hence, proposing a system performing detection and classification by using Deep Learning Algorithms using ConvolutionNeural Network (CNN), Artificial Neural Network (ANN), and TransferLearning (TL) would be helpful to doctors all around the world.\n\n\n**Summary**\n\nBrain Tumors are complex. There are a lot of abnormalities in the sizes and location of the brain tumor(s). This makes it really difficult for complete understanding of the nature of the tumor. Also, a professional Neurosurgeon is required for MRI analysis. Often times in developing countries the lack of skillful doctors and lack of knowledge about tumors makes it really challenging and time-consuming to generate reports from MRI‚Äô. So an automated system on Cloud can solve this problem.\n\n**Read More About Dataset:** [Click](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri)\n\n**The key folders in the dataset include:**\n\n1. GLIOMA TUMOR\n1. MENINGIOMA TUMOR\n1. NO TUMOR\n1. PITUITARY TUMOR\n\n\n\nRemote source:https://github.com/sartajbhuvaji/brain-tumor-classification-dataset\nThe folder contains MRI data. The images are already split into Training and Testing folders.\nEach folder has more four subfolders. These folders have MRIs of respective tumor classes.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n\n<p style=\"font-family:FRIZON; font-weight:normal; letter-spacing: 1px; color:#004C88; font-size:200%; text-align:left;padding: 10px; border-bottom: 3px solid #0081E5;\">1. Import Necessary Library</p>\n\n<a class=\"btn\" href=\"#home\">üè† Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping , ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical,plot_model\n\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-11-18T06:58:33.948146Z","iopub.execute_input":"2023-11-18T06:58:33.948537Z","iopub.status.idle":"2023-11-18T06:58:33.958865Z","shell.execute_reply.started":"2023-11-18T06:58:33.948505Z","shell.execute_reply":"2023-11-18T06:58:33.957838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n\n<p style=\"font-family:FRIZON; font-weight:normal; letter-spacing: 1px; color:#004C88; font-size:200%; text-align:left;padding: 10px; border-bottom: 3px solid #0081E5;\">2. Data Loading and Preprocessing</p>\n\n<a class=\"btn\" href=\"#home\">üè† Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"train_datasets = \"../input/brain-tumor-classification-mri/Training/\"\nvalidation_datasets = \"../input/brain-tumor-classification-mri/Testing/\"","metadata":{"execution":{"iopub.status.busy":"2023-11-18T06:45:41.472522Z","iopub.execute_input":"2023-11-18T06:45:41.472928Z","iopub.status.idle":"2023-11-18T06:45:41.477418Z","shell.execute_reply.started":"2023-11-18T06:45:41.472892Z","shell.execute_reply":"2023-11-18T06:45:41.476395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nimage_size = 224","metadata":{"execution":{"iopub.status.busy":"2023-11-18T07:29:28.211514Z","iopub.execute_input":"2023-11-18T07:29:28.212414Z","iopub.status.idle":"2023-11-18T07:29:28.218018Z","shell.execute_reply.started":"2023-11-18T07:29:28.212374Z","shell.execute_reply":"2023-11-18T07:29:28.216495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef prepare_the_datasets(train_datasets, validation_datasets, batch_size, image_size):\n\n    train_datasets_generator = ImageDataGenerator(rescale=1./255,\n                                                  shear_range = 0.2, \n                                                  zoom_range = 0.2, \n                                                  horizontal_flip = True, \n                                                  fill_mode = \"nearest\")\n\n\n    validation_datasets_generator = ImageDataGenerator(rescale=1.0/255)\n\n\n    train_datasets_generator_data = train_datasets_generator.flow_from_directory(\n        batch_size = batch_size,\n        directory = train_datasets,\n        shuffle = True,\n        target_size = (image_size, image_size),\n        class_mode = \"categorical\"\n    )\n\n    validation_datasets_generator_data = validation_datasets_generator.flow_from_directory(\n        batch_size = batch_size,\n        directory = validation_datasets,\n        shuffle = True,\n        target_size = (image_size, image_size),\n        class_mode = \"categorical\"\n    )\n\n\n    return train_datasets_generator_data, validation_datasets_generator_data","metadata":{"execution":{"iopub.status.busy":"2023-11-18T06:45:55.474951Z","iopub.execute_input":"2023-11-18T06:45:55.475950Z","iopub.status.idle":"2023-11-18T06:45:55.482376Z","shell.execute_reply.started":"2023-11-18T06:45:55.475913Z","shell.execute_reply":"2023-11-18T06:45:55.481474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data , validation_data = prepare_the_datasets(train_datasets, validation_datasets, batch_size, image_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T06:46:24.196013Z","iopub.execute_input":"2023-11-18T06:46:24.196395Z","iopub.status.idle":"2023-11-18T06:46:24.691483Z","shell.execute_reply.started":"2023-11-18T06:46:24.196364Z","shell.execute_reply":"2023-11-18T06:46:24.690750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n\n<p style=\"font-family:FRIZON; font-weight:normal; letter-spacing: 1px; color:#004C88; font-size:200%; text-align:left;padding: 10px; border-bottom: 3px solid #0081E5;\">3. DenseNet201 function Calling </p>\n\n<a class=\"btn\" href=\"#home\">üè† Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"<h3 align=\"left\"><font color='#E83500'>üí° Note:</font></h3>\n    \nEach Keras Application expects a specific kind of input preprocessing. For DenseNet, call tf.keras.applications.densenet.preprocess_input on your inputs before passing them to the model.\n\n**Arguments**\n\n**1. include_top:** whether to include the fully-connected layer at the top of the network.\n\n**1. weights:** one of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n\n**1. input_tensor:** optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n\n**1. input_shape:** optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n\n**1. pooling:** Optional pooling mode for feature extraction when include_top is False.\n> **None means** that the output of the model will be the 4D tensor output of the last convolutional block.\n\n> **avg means** that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor.\n\n> **max means** that global max pooling will be applied.\n\n**1. classes:** optional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified.\n\n**1. classifier_activation:** A str or callable. The activation function to use on the \"top\" layer. Ignored unless include_top=True. \nSet classifier_activation=None to return the logits of the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\".\n\nFrom [Keras Application website](https://keras.io/api/applications/densenet/#densenet201-function)","metadata":{}},{"cell_type":"code","source":"densenet= tf.keras.applications.DenseNet201(\n    include_top=False,\n    weights=\"imagenet\",\n    pooling=None,\n    input_shape=(224,224,3)\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:11:27.374384Z","iopub.execute_input":"2023-11-18T08:11:27.375547Z","iopub.status.idle":"2023-11-18T08:11:32.724878Z","shell.execute_reply.started":"2023-11-18T08:11:27.375505Z","shell.execute_reply":"2023-11-18T08:11:32.723998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in densenet.layers:\n    layer.trainable= False","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:11:55.042086Z","iopub.execute_input":"2023-11-18T08:11:55.042827Z","iopub.status.idle":"2023-11-18T08:11:55.073769Z","shell.execute_reply.started":"2023-11-18T08:11:55.042784Z","shell.execute_reply":"2023-11-18T08:11:55.072766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Creates the top or head of the model that will be placed on top of the layers \"\"\"\n\ndef addTopModel(bottom_model, num_class, D=256):\n    top_model= bottom_model.output\n    top_model= Flatten(name=\"flatten\") (top_model)\n    top_model= Dense(D, activation=\"relu\") (top_model)\n    top_model= Dropout(0.3) (top_model)\n    top_model= Dense(num_class, activation=\"softmax\") (top_model)\n    return top_model","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:11:57.702286Z","iopub.execute_input":"2023-11-18T08:11:57.703090Z","iopub.status.idle":"2023-11-18T08:11:57.708835Z","shell.execute_reply.started":"2023-11-18T08:11:57.703052Z","shell.execute_reply":"2023-11-18T08:11:57.707756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes= 4\nFc_Head= addTopModel(densenet, num_classes)\nmodel= Model(inputs= densenet.input, outputs= Fc_Head)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:12:00.336528Z","iopub.execute_input":"2023-11-18T08:12:00.337499Z","iopub.status.idle":"2023-11-18T08:12:00.423807Z","shell.execute_reply.started":"2023-11-18T08:12:00.337459Z","shell.execute_reply":"2023-11-18T08:12:00.422773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint= ModelCheckpoint(\"/Trained Models/densenet101.h5\",\n                            monitor= \"val_loss\",\n                            mode= \"min\",\n                            save_best_only= True,\n                            verbose=1)\n\nearlystop= EarlyStopping(monitor= \"val_loss\",\n                         min_delta= 0,\n                         patience= 3,\n                         verbose=1,\n                         restore_best_weights= True)\n\n\nreduce_lr= ReduceLROnPlateau(monitor= \"val_loss\",\n                         factor=0.2,   \n                         patience= 5,\n                         verbose=1,\n                         min_delta= 0.000001)\n\n\ncallbacks=[earlystop, checkpoint, reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:12:29.649992Z","iopub.execute_input":"2023-11-18T08:12:29.650396Z","iopub.status.idle":"2023-11-18T08:12:29.657250Z","shell.execute_reply.started":"2023-11-18T08:12:29.650361Z","shell.execute_reply":"2023-11-18T08:12:29.656018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss= 'categorical_crossentropy',\n              optimizer= RMSprop(learning_rate=0.00001),\n              metrics= ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:12:32.008462Z","iopub.execute_input":"2023-11-18T08:12:32.009178Z","iopub.status.idle":"2023-11-18T08:12:32.037268Z","shell.execute_reply.started":"2023-11-18T08:12:32.009143Z","shell.execute_reply":"2023-11-18T08:12:32.036259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_train_samples= 2870\nnb_validation_samples= 394\nepochs= 20\nbatch_size= 128\n\nhistory= model.fit(train_data,\n                   steps_per_epoch= nb_train_samples//batch_size,\n                   epochs= epochs,\n                   callbacks=callbacks,\n                   validation_data= validation_data,\n                   validation_steps= nb_validation_samples//batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:12:35.426678Z","iopub.execute_input":"2023-11-18T08:12:35.427672Z","iopub.status.idle":"2023-11-18T08:16:37.143679Z","shell.execute_reply.started":"2023-11-18T08:12:35.427633Z","shell.execute_reply":"2023-11-18T08:16:37.142701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation= model.evaluate(validation_data, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:21:53.694507Z","iopub.execute_input":"2023-11-18T08:21:53.695306Z","iopub.status.idle":"2023-11-18T08:21:55.691071Z","shell.execute_reply.started":"2023-11-18T08:21:53.695268Z","shell.execute_reply":"2023-11-18T08:21:55.690204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n\n<p style=\"font-family:FRIZON; font-weight:normal; letter-spacing: 1px; color:#004C88; font-size:200%; text-align:left;padding: 10px; border-bottom: 3px solid #0081E5;\">5. Now Plot the Training Loss, Validation Loss, Training Accuracy, Validation Accuracy</p>\n\n<a class=\"btn\" href=\"#home\">üè† Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef plot_training_curves(history):\n    loss= np.array(history.history['loss'])\n    val_loss= np.array(history.history['val_loss'])\n    \n    accuracy= np.array(history.history['accuracy'])\n    val_accuracy= np.array(history.history['val_accuracy'])\n    \n    epochs= range(len(history.history['loss']))\n    \n    fig, (ax1, ax2)= plt.subplots(1,2,figsize=(10,3))\n    \n    #plot loss\n    ax1.plot(epochs, loss, label='traing_loss', marker='o')\n    \n    ax1.plot(epochs, val_loss, label='val_loss', marker='o')\n    \n    ax1.fill_between(epochs,loss, val_loss, where=(loss>val_loss),color='C0',alpha=0.3,interpolate=True)\n    ax1.fill_between(epochs,loss, val_loss, where=(loss<val_loss),color='C1',alpha=0.3,interpolate=True)\n    \n    ax1.set_title('Loss(Lower Means Better)',fontsize= 16)\n    ax1.set_xlabel('Epochs', fontsize=10)\n    \n    ax1.legend()\n    \n    #plot Accuracy\n    ax2.plot(epochs, accuracy, label='traing_accuracy', marker='o')\n    \n    ax2.plot(epochs, val_accuracy, label='val_accuracy', marker='o')\n    \n    ax2.fill_between(epochs,accuracy, val_accuracy, where=(accuracy>val_accuracy),color='C0',alpha=0.3,interpolate=True)\n    ax2.fill_between(epochs,accuracy, val_accuracy, where=(accuracy<val_accuracy),color='C1',alpha=0.3,interpolate=True)\n    \n    ax2.set_title('Accuracy(Higher Means Better)',fontsize= 16)\n    ax2.set_xlabel('Epochs', fontsize=10)\n    \n    ax2.legend()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:17:05.346611Z","iopub.execute_input":"2023-11-18T08:17:05.347031Z","iopub.status.idle":"2023-11-18T08:17:05.359324Z","shell.execute_reply.started":"2023-11-18T08:17:05.346996Z","shell.execute_reply":"2023-11-18T08:17:05.358065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training_curves(history)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:17:09.382600Z","iopub.execute_input":"2023-11-18T08:17:09.383344Z","iopub.status.idle":"2023-11-18T08:17:09.968538Z","shell.execute_reply.started":"2023-11-18T08:17:09.383297Z","shell.execute_reply":"2023-11-18T08:17:09.967550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n\n<p style=\"font-family:FRIZON; font-weight:normal; letter-spacing: 1px; color:#004C88; font-size:200%; text-align:left;padding: 10px; border-bottom: 3px solid #0081E5;\">6. Now Predictions for random image\n</p>\n\n<a class=\"btn\" href=\"#home\">üè† Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.imagenet_utils import preprocess_input\nimg= image.load_img(\"../input/brain-tumor-classification-mri/Testing/no_tumor/image(10).jpg\",target_size=(224,224))\n\nx= image.img_to_array(img)\nx=x/255\nx= np.expand_dims(x, axis=0)\nimg_data=preprocess_input(x)\nimg_data.shape\npreds= model.predict(x)\npreds= np.argmax(preds, axis=1)\nif preds==1:\n    preds=\"The image is glima Tumor\"\nelif preds==2:\n    preds=\"The image is meningioma Tumor\"\nelif preds==3:\n    preds=\"The image is No Tumor\"\nelse:\n    preds=\"The image is pituitary tumor\"\nprint(preds)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:23:07.121394Z","iopub.execute_input":"2023-11-18T08:23:07.121828Z","iopub.status.idle":"2023-11-18T08:23:10.468454Z","shell.execute_reply.started":"2023-11-18T08:23:07.121795Z","shell.execute_reply":"2023-11-18T08:23:10.467484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Saving on directory\n\nmodel.save(\"../working/densenet101.h5\")\ny_pred= model.predict(validation_data)\nprint(y_pred)\ny_pred= np.argmax(y_pred, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T08:30:46.139182Z","iopub.execute_input":"2023-11-18T08:30:46.140109Z","iopub.status.idle":"2023-11-18T08:30:49.830673Z","shell.execute_reply.started":"2023-11-18T08:30:46.140072Z","shell.execute_reply":"2023-11-18T08:30:49.829623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n**Please feel free to ask in the comment section if you have any confusion or questions.**\n\n**Here are some of the contributions I've made on Kaggle:**\n1. [Pie Charts in Python](https://www.kaggle.com/code/alsaniipe/pie-charts-in-python)\n1. [Scatter plots with Plotly Express](https://www.kaggle.com/code/alsaniipe/scatter-plots-with-plotly-express)\n1. [X-ray Image Classification using Transfer Learning](https://www.kaggle.com/code/alsaniipe/x-ray-image-classification-using-transfer-learning)\n1. [Flowers Classification by Using VGG16 Model üéâüéâ](https://www.kaggle.com/code/alsaniipe/flowers-classification-by-using-vgg16-model)\n1. [Car Brand Prediction's by Using ResNet50 Model](https://www.kaggle.com/code/alsaniipe/car-brand-prediction-s-by-using-resnet50-model)\n1. [Image Preprocessing-Morpological Analysis & Kernel](https://www.kaggle.com/code/alsaniipe/image-preprocessing-morpological-analysis-kernel)\n1. [Image Similarity Index (SSIM analysis )](https://www.kaggle.com/code/alsaniipe/image-similarity-index-ssim-analysis)\n1. [Image Preprocessing- Image Transformation & OpenCV](https://www.kaggle.com/code/alsaniipe/image-preprocessing-image-transformation-opencv)","metadata":{}}]}